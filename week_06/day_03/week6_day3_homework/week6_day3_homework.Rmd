---
title: "R Notebook"
output: html_notebook
---
```{r}
library(tidyverse)
library(janitor)
library(infer)
```

Task 1.
Load the data again, clean_names(), and re-familiarise yourself with it
```{r}
ames <- read_csv("ames.csv") %>%
  clean_names()
```

Task 2.
Investigate the distribution of lot_area. Is the distribution roughly normal? If not, what problems do you find?
```{r}
ames %>%
  ggplot() +
  geom_histogram(aes(x = lot_area))

# No. It is heavily right skewed. 
```

Task 3.
Compute and visualise a bootstrap sampling distribution for the mean(lot_area) of the sold houses.
```{r}
# bootstrap_resample_200 <- ames %>%
#   rep_sample_n(size = 200, replace = TRUE, reps = 5000) %>%
#   summarise(mean_lot_area = mean(lot_area))
# 
# bootstrap_resample_200 %>%
#   ggplot() +
#   geom_histogram(aes(x = mean_lot_area))


lot_area_resample <- ames %>%
  specify(response= lot_area) %>%
  generate(reps = 5000, type = "bootstrap") %>%
  calculate(stat = "mean")

infer_ci_lot <- lot_area_resample %>%
  get_ci(level = 0.95, type = "percentile")

lot_area_resample %>%
  visualise(bins = 30) +
  shade_ci(endpoints = infer_ci_lot)

```

Task 4.
Use your bootstrap distribution to calculate a 95%

CI for mean(lot_area), and visualise it on the distribution
```{r}
# as above
```

Task 5.
You would like to know the mean(lot_area) of the sold houses with higher confidence. Calculate the 99%
CI for this variable (you can re-use your bootstrap distribution from above). Is it narrower or broader than the 95%

CI? Does that make sense?
```{r}
infer_ci_99 <- lot_area_resample %>%
  get_ci(level = 0.99, type = "percentile")
lot_area_resample %>%
  visualise(bins = 30) +
  shade_ci(endpoints = infer_ci_99)

# broader
```

Task 6.
Calculate the point estimate of the mean(lot_area)
```{r}
mean_lot <- lot_area_resample %>%
  summarise(mean = mean(stat))
mean_lot


```


Extension
Task 1.
Calculate a point estimate and 95% CI for the proportion of houses in the data built before 1920. Does the number of reps you use matter? [Investigate reps from 200 up to 50000, memory of your laptop permitting]. 

```{r}
pre_1920_ames <- ames %>%
  select(lot_area, year_built) %>%
  filter(year_built <= 1920)

# create resample
bootstrap_pre_1920 <- pre_1920_ames %>%
  specify(response = lot_area) %>%
  generate(reps = 200, type = "bootstrap") %>%
  calculate(stat = "mean")

# calculate CI
bootstrap_pre_1920_ci <- bootstrap_pre_1920 %>%
  get_ci(level = 0.95, type = "percentile")

bootstrap_pre_1920 %>%
  visualise(bins = 30) +
  shade_ci(endpoints = bootstrap_pre_1920_ci)

mean_bootstrap_pre_1920 <- bootstrap_pre_1920 %>%
  summarise(mean = mean(stat))
mean_bootstrap_pre_1920


# I started from 200, and ran the code multiple times
# (without saving to variables), and observed that as the reps increased, the 
# distribution became more normalised (stopping at 20000)


bootstrap_pre_1920_20k <- pre_1920_ames %>%
  specify(response = lot_area) %>%
  generate(reps = 20000, type = "bootstrap") %>%
  calculate(stat = "mean")

# calculate CI
bootstrap_pre_1920_ci_20k <- bootstrap_pre_1920_20k %>%
  get_ci(level = 0.95, type = "percentile")

bootstrap_pre_1920_20k %>%
  visualise(bins = 30) +
  shade_ci(endpoints = bootstrap_pre_1920_ci)

mean_bootstrap_pre_1920_20k <- bootstrap_pre_1920_20k %>%
  summarise(mean = mean(stat))
mean_bootstrap_pre_1920_20k

```

