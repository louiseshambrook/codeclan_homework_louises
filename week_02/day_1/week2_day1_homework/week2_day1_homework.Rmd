---
title: "R Notebook"
output: html_notebook
---

```{r}
library(tidyverse)
library(janitor)

card_base <- read_csv("data/CardBase.csv")
customer_base <- read_csv("data/CustomerBase.csv")
fraud_base <- read_csv("data/FraudBase.csv")
transaction_base <- read_csv("data/TransactionBase.csv")

```

```{r}
# 1.1 Joins

# Question 1
# Read in all 4 credit card transaction datasets and clean column names.

card_database <- card_base %>%
  clean_names()

customer_database <- customer_base %>%
    clean_names()

fraud_database <- fraud_base %>%
    clean_names()

transaction_database <- transaction_base %>%
    clean_names()

```

```{r}
# Question 2
# Join the data containing card details and customer details by customer id, so that all records of card details and any matching records in customer details are kept. Before you run the code, think about how many rows you expect to see after joining.

left_join(card_database, customer_database, by = "cust_id")

# how many I expect - 500 ? there are 500 card ID's, and I want to join customer
# id's, WHERE POSSIBLE

# - after joining, correct. 



```


```{r}
# Question 3
# Join the data containing fraud details with transaction details so all rows of both tables are kept. What does the resulting row number tell you?

full_join(fraud_database, transaction_database, by = "transaction_id")

#resulting row count - 10k. - it has pulled all the transaction values across?
# so ... not a lot?

```

```{r}
# Question 4
# Join the data containing card details with transaction details so rows from card details which have matching ones in the second are returned, but only return rows in the first table once.

semi_join(card_database, transaction_database,
          by = c("card_number" = "credit_card_id"))

```

```{r}
# 1.2 tidyr
# Question 5
# Read in hat_observations and separate observation into two columns, hat_colour and hat_type.

hat_data <- read_csv("data/hat_observations.csv")

hat_data_separated <- hat_data %>%
  separate(observation, c("hat_colour", "hat_type"), sep = ",")


hat_observations <- read_csv("data/hat_observations.csv")

```

```{r}
# Question 6
# Unite day, month, and year columns into a column called date using a suitable separator. Then find the date where the most berets were observed.

hat_data_dates <- hat_data_separated %>%
  unite(date, c("day", "month", "year"),
        sep = "/"
  )

hat_data_dates %>%
  filter(hat_type == "beret") %>%
  slice_max(observation_count)


# correct answer - because there are two dates that are on separate rows
hat_data_dates %>% 
  filter(hat_type == "beret") %>% 
  group_by(date) %>% 
  summarise(total = sum(observation_count)) %>% 
  slice_max(total)

```


```{r}
# 2 Extension
# 2.1 Joins
# Question 1
# Can you join all 4 datasets together so that youâ€™re left with a dataset that looks like below with 109 rows and 12 columns?

ext_database <- inner_join(transaction_database,
          fraud_database, by = "transaction_id") %>%
  inner_join(card_database,
           by = c("credit_card_id" = "card_number")) %>%
  left_join(customer_database, by = "cust_id")

```

```{r}
# 2.2 tidyr
# Question 2
# Read in exam_scores and transform it into long format with two new columns exam_question and score. Then, using separate and select, remove superfluous information from the values in exam_question

#answer - didn't complete
exam_scores <- read_csv("data/exam_scores.csv")

exam_scores_long <- exam_scores %>% 
  pivot_longer(exam_Q1:exam_Q10, names_to = "exam_question", values_to = "score") 

exam_scores_long %>% 
  separate(exam_question, sep = "Q", into = c("extra_column", "exam_question")) %>% 
  select(-extra_column)


```


