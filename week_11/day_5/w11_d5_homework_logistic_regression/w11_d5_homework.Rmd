---
title: "R Notebook"
output: html_notebook
---

Week 11 Day 5 Logistic Regression Homework

You have been provided with a set of data on customer purchases of either ‘Citrus Hill’ (purchase = 'CH') or ‘Minute Maid’ (purchase = 'MM') orange juice, together with some further attributes of both the customer and the store of purchase. A data dictionary is also provided in the data directory.

We would like you to build the best predictive classifier you can of whether a customer is likely to buy Citrus Hill or Minute Maid juice. Use logistic regression to do this. You should use either train-test splitting or cross-validation to evaluate your classifier. The metric for ‘best classifier’ will be highest AUC value either in the test set (for train-test splitting) or from cross-validation.

Tips:
- can do automated, or manual
- the purchase variable will require wrangling
- wrangle other categorical variables into factors
- weekofpurchase is also tough; decide on a stategy
- check for aliased variables

```{r}
# loading libraries

library(tidyverse)
library(janitor)
library(GGally)
library(janitor)
library(modelr)
library(broom)
library(pROC)
library(caret)

```

```{r}
# loading data

juice <- read_csv("data/orange_juice.csv")
```

```{r}
# getting overview of data / EDA
head(juice)
```

```{r}
# looking closer at weekofpurchase - the problem is similar to the one in the PDA task

juice %>%
  select(WeekofPurchase) %>%
  distinct(WeekofPurchase) %>%
  arrange(WeekofPurchase)

# there are 52 distinct rows, i.e. 1 per week. They can't be converted into months (would be 4.3), but they CAN be converted into quarters (13)
```

```{r}
# cleaning the data

juice_clean <- juice %>%
  clean_names() %>%
  mutate(purchase_mm = as.factor(ifelse(purchase == "MM", "T", "F")),
         store_id = as.factor(store_id),
         special_ch = as.factor(special_ch),
         special_mm = as.factor(special_mm),
         store7 = as.factor(store7),
         store = as.factor(store)) %>%
  select(-purchase, -weekof_purchase)


```

Checking for aliased variables
```{r}
alias(purchase_mm ~ ., data = juice_clean)
```
There are multiple here which are aliased.

```{r}
# removing aliased variables
juice_clean <- juice_clean %>%
  select(-store_id, -price_ch, -sale_price_ch, -disc_mm, -list_price_diff, -store7)

```

Examining relationships using ggpairs
```{r}
juice_clean %>%
  ggpairs()
```

This initial plot is hard to read, so I will split it up
```{r}
juice_clean %>%
  select(purchase_mm, price_mm, disc_ch, special_ch, special_mm, store) %>%
  ggpairs()
```

```{r}
juice_clean %>%
  select(purchase_mm, loyal_ch, sale_price_mm, price_diff, pct_disc_mm, pct_disc_ch) %>%
  ggpairs()
```

Based on the plots, the variables price_diff appears to have an impact.
As does loyal_ch (there is a large variance in the mean).
The store could also have an impact, but this could vary across the 5 levels.
Lastly, sale_price, and special_ch, and special_mm, could also impact the model.

Therefore, I will include in my model:
loyal_ch
store
sale_price
special

Building 1st test model, with loyal_ch
```{r}
juice_model_1a <- glm(purchase_mm ~ loyal_ch,
                   data = juice_clean,
                   family = binomial(link = "logit"))

juice_1a_with_pred <- juice_clean %>%
  add_predictions(juice_model_1a, type = "response")

tidy(juice_model_1a)

roc_1a_pred <- juice_1a_with_pred %>%
  roc(response = purchase_mm, predictor = pred)

auc(roc_1a_pred)

```

Building 2nd test model, with store
```{r}
juice_model_1b <- glm(purchase_mm ~ store,
                   data = juice_clean,
                   family = binomial(link = "logit"))

juice_1b_with_pred <- juice_clean %>%
  add_predictions(juice_model_1b, type = "response")

tidy(juice_model_1b)

roc_1b_pred <- juice_1b_with_pred %>%
  roc(response = purchase_mm, predictor = pred)

auc(roc_1b_pred)

```
This is a stat sig model - but the AUC is less than loyal_ch.

```{r}
juice_model_1c <- glm(purchase_mm ~ sale_price_mm,
                   data = juice_clean,
                   family = binomial(link = "logit"))

juice_1c_with_pred <- juice_clean %>%
  add_predictions(juice_model_1c, type = "response")

tidy(juice_model_1c)

roc_1c_pred <- juice_1c_with_pred %>%
  roc(response = purchase_mm, predictor = pred)

auc(roc_1c_pred)
```
This is also less than the 1st model.

```{r}
juice_model_1d <- glm(purchase_mm ~ special_mm,
                   data = juice_clean,
                   family = binomial(link = "logit"))

juice_1d_with_pred <- juice_clean %>%
  add_predictions(juice_model_1d, type = "response")

tidy(juice_model_1d)

roc_1d_pred <- juice_1d_with_pred %>%
  roc(response = purchase_mm, predictor = pred)

auc(roc_1d_pred)
```
This is the lowest. Therefore, I will go with the first one, loyal_ch.

The first one I will try to add on, is store.
```{r}
juice_model_2a <- glm(purchase_mm ~ loyal_ch + store,
                   data = juice_clean,
                   family = binomial(link = "logit"))

juice_2a_with_pred <- juice_clean %>%
  add_predictions(juice_model_2a, type = "response")

tidy(juice_model_2a)

roc_2a_pred <- juice_2a_with_pred %>%
  roc(response = purchase_mm, predictor = pred)

auc(roc_2a_pred)
```
This is marginally higher than loyal_ch alone, but still stat sign.

I will next try with sale_price_mm.
```{r}
juice_model_2b <- glm(purchase_mm ~ loyal_ch + sale_price_mm,
                   data = juice_clean,
                   family = binomial(link = "logit"))

juice_2b_with_pred <- juice_clean %>%
  add_predictions(juice_model_2b, type = "response")

tidy(juice_model_2b)

roc_2b_pred <- juice_2b_with_pred %>%
  roc(response = purchase_mm, predictor = pred)

auc(roc_2b_pred)
```
This is also stat sign, and marginally higher still than store.

I will next try with special_mm.
```{r}
juice_model_2c <- glm(purchase_mm ~ loyal_ch + special_mm,
                   data = juice_clean,
                   family = binomial(link = "logit"))

juice_2c_with_pred <- juice_clean %>%
  add_predictions(juice_model_2c, type = "response")

tidy(juice_model_2c)

roc_2c_pred <- juice_2c_with_pred %>%
  roc(response = purchase_mm, predictor = pred)

auc(roc_2c_pred)
```
This is lower. Therefore, the best model so far is purchase_mm ~ loyal_ch + sale_price_mm, which is model juice_model_2c.

Next, I will plot the data.
```{r}
ggroc(data = list(juice_model_2c = roc_2c_pred),
      legacy.axes = TRUE) +
  coord_fixed()
```
Visually, this looks like a good model.


For the sake of comparison, I'll compare it to the other models.
```{r}
ggroc(data = list(juice_model_2c = roc_2c_pred,
                  juice_model_2b = roc_2b_pred,
                  juice_model_2a = roc_2a_pred,
                  juice_model_1d = roc_1d_pred,
                  juice_model_1c = roc_1c_pred,
                  juice_model_1b = roc_1b_pred,
                  juice_model_1a = roc_1a_pred),
      legacy.axes = TRUE) +
  coord_fixed()
```
Interestingly, this shows that one model may have had a higher AUC (2b). I will check.

From checking the AUC values I calculated above, it is correct that model 2b is higher. Having used model 2c is a typographical error in my documentation, so it was good that I checked using the plot.

The correct model is 2b, as the AUC is slightly higher than 2c (as above in my calculations).

Lastly, I will now complete cross validation.

```{r}
# train the model
train_control <- trainControl(method = "repeatedcv",
                              number = 5,
                              repeats = 100,
                              savePredictions = TRUE,
                              classProbs = TRUE,
                              summaryFunction = twoClassSummary)
```

```{r}
validation_model_1 <- train(purchase_mm ~ loyal_ch + sale_price_mm,
               data = juice_clean,
               trControl = train_control,
               method = "glm",
               family = binomial(link = "logit"))

summary(validation_model_1)
validation_model_1$results
# this is throwing an error for the logical type column. ??
```
I've used cross-validation to test/validate my model; it has a sensitivity of 86% and specificity of 73%. Therefore, it is reasonably good at using purchase_mm as a classifier for whether a customer is likely to buy citrus hill, or minute maid. 
